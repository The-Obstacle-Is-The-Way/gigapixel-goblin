# Results Directory Cleanup & Reorganization Plan

**Date**: 2026-01-01
**Status**: EXECUTED (archived to `results/_archive/pre-2026-01-01-fixes-20260101_192426/`)

## Executive Summary

The `results/` directory is cluttered with:
- Benchmark artifacts generated before the 2026-01-01 fixes (BUG-040/041/042); GTEx/TCGA/PANDA are also pre-BUG-038 parsing hardening
- Backup files (`.bak`) from a Dec 30 backup operation
- Multiple timestamped runs from development iteration
- Empty/incomplete smoke test directories
- Legacy e2e validation outputs from Dec 18

**Action taken**: Archived all existing artifacts (including `e2e_validation/`) and deleted `.bak` + `smoke-*` noise. Ready for fresh reruns with BUG-038/040/041/042 fixes.

---

## Current Directory Inventory

**Validated via**: `stat` (bytes + mtime) and `du -sh` on 2026-01-01 (pre-cleanup inventory).

### Root Level Files (`results/`)

| File | Size | Last Modified | Origin | Verdict |
|------|------|---------------|--------|---------|
| `gtex_giant_openai_gpt-5.2_results.json` | 62894 B (61K) | 2025-12-30 20:21:14 -0500 | Main GTEx run | **ARCHIVE** |
| `gtex_giant_openai_gpt-5.2_results.json.bak` | 62324 B (61K) | 2025-12-30 17:34:05 -0500 | Backup | **DELETE** |
| `panda_giant_openai_gpt-5.2_results.json` | 211777 B (207K) | 2025-12-30 20:21:14 -0500 | Main PANDA run | **ARCHIVE** |
| `panda_giant_openai_gpt-5.2_results.json.bak` | 210422 B (205K) | 2025-12-30 17:34:05 -0500 | Backup | **DELETE** |
| `tcga_giant_openai_gpt-5.2_results.json` | 76500 B (75K) | 2025-12-30 20:21:15 -0500 | Main TCGA run | **ARCHIVE** |
| `tcga_giant_openai_gpt-5.2_results.json.bak` | 75928 B (74K) | 2025-12-30 17:34:05 -0500 | Backup | **DELETE** |
| `tcga_giant_openai_gpt-5.2_20251221_162833_results.json` | 9502 B (9.3K) | 2025-12-30 17:34:05 -0500 | Old partial TCGA run | **ARCHIVE** (partial) |
| `tcga_giant_openai_gpt-5.2_20251221_162833_results.json.bak` | 9498 B (9.3K) | 2025-12-30 17:34:05 -0500 | Backup of partial | **DELETE** |
| `tcga_expert_vqa_giant_openai_gpt-5.2_results.json` | 36869 B (36K) | 2025-12-30 21:18:30 -0500 | ExpertVQA run | **ARCHIVE** |
| `tcga_slidebench_giant_openai_gpt-5.2_results.json` | 57017 B (56K) | 2025-12-30 21:34:52 -0500 | SlideBench run | **ARCHIVE** |
| `gtex-benchmark-20251227-010151.log` | 81550 B (80K) | 2025-12-27 01:16:44 -0500 | Console log (referenced in bug docs) | **ARCHIVE** |
| `tcga-benchmark-20251227-084052.log` | 130176 B (127K) | 2025-12-27 09:09:52 -0500 | Console log (referenced in bug docs) | **ARCHIVE** |
| `panda_benchmark.log` | 281945 B (275K) | 2025-12-29 12:36:41 -0500 | Console log (referenced in bug docs) | **ARCHIVE** |

**Important**: Filesystem `mtime` is **not** the same as the benchmark run time. The benchmark run time is recorded in each results JSON under `timestamp` (UTC). For these files:

| Results JSON | Embedded `timestamp` (UTC) |
|-------------|-----------------------------|
| `gtex_giant_openai_gpt-5.2_results.json` | `2025-12-27T06:16:44.582723+00:00` |
| `tcga_giant_openai_gpt-5.2_results.json` | `2025-12-27T14:09:52.234269+00:00` |
| `panda_giant_openai_gpt-5.2_results.json` | `2025-12-29T17:36:41.813717+00:00` |
| `tcga_expert_vqa_giant_openai_gpt-5.2_results.json` | `2025-12-31T02:18:30.489070+00:00` |
| `tcga_slidebench_giant_openai_gpt-5.2_results.json` | `2025-12-31T02:34:52.839742+00:00` |
| `tcga_giant_openai_gpt-5.2_20251221_162833_results.json` | `2025-12-21T16:35:43.157408+00:00` |

### Subdirectories

| Directory | Contents | Size (`du -sh`) | Verdict |
|-----------|----------|-----------------|---------|
| `checkpoints/` | 6 checkpoint files (resume state) | 476K | **ARCHIVE** |
| `trajectories/` | 918 trajectory JSON files | 1.7G | **ARCHIVE** |
| `e2e_validation/` | Dec 18 dev validation outputs | 1.8M | **ARCHIVE** |
| `smoke-20251230-153836/` | Empty directory | 0B | **DELETE** |
| `smoke-20251230-154052/` | 1 result + 1 trajectory + 1 checkpoint | 332K | **DELETE** |

---

## Provenance Analysis

### Where Results Come From

Results are generated by `giant benchmark <dataset>` command:

```
src/giant/cli/main.py           # CLI entry point
  └── src/giant/cli/runners.py  # Benchmark runner
       └── src/giant/eval/runner.py  # EvaluationOrchestrator
            ├── src/giant/eval/executor.py  # Per-item execution
            ├── src/giant/eval/persistence.py  # File I/O
            └── src/giant/eval/resumable.py  # Checkpoints
```

**File naming patterns**:
- Results: `{run_id}_results.json` (`src/giant/eval/persistence.py:74-78`)
- Trajectories: `trajectories/{safe_item_id}_run{run_idx}.json` (`src/giant/eval/persistence.py:54-72`)
- Checkpoints: `checkpoints/{run_id}.checkpoint.json` (`src/giant/eval/resumable.py:110-120`)

**Run ID generation (CLI path)**:
- Base run ID (deterministic): `{dataset}_{mode}_{provider}_{model}` (`src/giant/cli/runners.py:687-702`)
- Default `giant benchmark` uses `--resume` so the base run ID is used as-is (no timestamp).
- If `--no-resume`, the CLI appends `_{YYYYMMDD_HHMMSS}` (`src/giant/cli/runners.py:628-636`).

**Run ID generation (fallback, non-CLI call-sites)**:
- If `BenchmarkRunner.run_benchmark(..., run_id=None)` is called directly, the orchestrator generates `{benchmark_name}_{YYYYMMDD_HHMMSS}` (`src/giant/eval/runner.py:175-191`).

### Why Results Are Pre-Fix

**Fix landing commits (git)**:
- **BUG-038** parsing/retry hardening: `f946536` (2025-12-29T23:26:45-05:00), `72df1b3` (2025-12-30T01:19:41-05:00)
- **BUG-040 P1-2** OpenAI schema constraints: `be1db7c` (2026-01-01T11:52:48-05:00)
- **BUG-041/BUG-042** paper-fidelity modes (fixed iterations + patch_vote): `159b9d9` (2026-01-01T17:08:50-05:00)

**Run timestamps (from results JSON `timestamp`, UTC)**:
- `tcga_giant_openai_gpt-5.2_20251221_162833_results.json`: 2025-12-21
- `gtex_giant_openai_gpt-5.2_results.json`: 2025-12-27
- `tcga_giant_openai_gpt-5.2_results.json`: 2025-12-27
- `panda_giant_openai_gpt-5.2_results.json`: 2025-12-29
- `tcga_expert_vqa_giant_openai_gpt-5.2_results.json`: 2025-12-31 (UTC; 2025-12-30 local)
- `tcga_slidebench_giant_openai_gpt-5.2_results.json`: 2025-12-31 (UTC; 2025-12-30 local)

**Conclusion**:
- All current main benchmark artifacts are **pre** BUG-040/041/042.
- GTEx/TCGA/PANDA (+ the old partial TCGA run) are also **pre** BUG-038.
- ExpertVQA/SlideBench were generated after BUG-038 landed but before BUG-040/041/042; they should still be archived under the “pre-2026-01-01 fixes” bucket.

The `.bak` files are from a Dec 30 17:34 backup operation (likely manual).

---

## Cleanup Steps

### Safety Dry-Run (Recommended)

Before moving/deleting anything, do a dry-run to see exactly what will be touched:

```bash
ARCHIVE_DIR="results/_archive/pre-2026-01-01-fixes-$(date +%Y%m%d_%H%M%S)"
mkdir -p "$ARCHIVE_DIR"

echo mv results/*_results.json "$ARCHIVE_DIR/"
echo mv results/*.log "$ARCHIVE_DIR/"
echo mv results/checkpoints "$ARCHIVE_DIR/"
echo mv results/trajectories "$ARCHIVE_DIR/"
echo mv results/e2e_validation "$ARCHIVE_DIR/"
echo rm -f results/*.bak
echo rm -rf results/smoke-*
```

Note: `results/` is gitignored (`.gitignore` contains `/results/`), so `_archive/` remains local and won’t affect version control.

### Phase 1: Archive (BEFORE rerun)

```bash
# Create timestamped archive
ARCHIVE_DIR="results/_archive/pre-2026-01-01-fixes-$(date +%Y%m%d_%H%M%S)"
mkdir -p "$ARCHIVE_DIR"

# Move main artifacts (results + logs + checkpoints + trajectories)
mv results/*_results.json "$ARCHIVE_DIR/"
mv results/*.log "$ARCHIVE_DIR/"
mv results/checkpoints "$ARCHIVE_DIR/"
mv results/trajectories "$ARCHIVE_DIR/"
mv results/e2e_validation "$ARCHIVE_DIR/" 2>/dev/null || true

# Create archive manifest
echo "Pre-2026-01-01 fixes results archive" > "$ARCHIVE_DIR/README.md"
echo "Created: $(date -Iseconds)" >> "$ARCHIVE_DIR/README.md"
echo "Contains artifacts generated before BUG-040/041/042 (paper-parity) fixes." >> "$ARCHIVE_DIR/README.md"
echo "Note: GTEx/TCGA/PANDA are also pre-BUG-038; ExpertVQA/SlideBench are post-BUG-038 but pre-BUG-040/041/042." >> "$ARCHIVE_DIR/README.md"
```

### Phase 2: Delete Noise

```bash
# Delete backup files
rm -f results/*.bak

# Delete empty/incomplete smoke test directories
rm -rf results/smoke-20251230-153836
rm -rf results/smoke-20251230-154052
```

### Phase 3: Clean Structure for Rerun

After cleanup, `results/` should contain:
```
results/
├── _archive/
│   └── pre-2026-01-01-fixes-YYYYMMDD_HHMMSS/
│       ├── README.md
│       ├── gtex_giant_openai_gpt-5.2_results.json
│       ├── panda_giant_openai_gpt-5.2_results.json
│       ├── tcga_giant_openai_gpt-5.2_results.json
│       ├── tcga_giant_openai_gpt-5.2_20251221_162833_results.json
│       ├── tcga_expert_vqa_giant_openai_gpt-5.2_results.json
│       ├── tcga_slidebench_giant_openai_gpt-5.2_results.json
│       ├── *.log
│       ├── e2e_validation/
│       │   ├── e2e_*_results.json
│       │   ├── checkpoints/
│       │   └── trajectories/
│       ├── checkpoints/
│       │   └── *.checkpoint.json
│       └── trajectories/
│           └── *.json (918 files)
```

---

## Hidden Dependency Check

- No **runtime** code in `src/` hardcodes `results/trajectories/` or expects specific result filenames. The only reference is a docstring example (`src/giant/eval/resumable.py:87`) which is illustrative, not executable.
- Unit tests referencing `/results/...` are schema/fixture strings and do not depend on the on-disk `results/` tree.

## Rerun Plan

After cleanup, execute fresh benchmarks with all fixes:

```bash
# Recommended run order (by dataset size)
uv run giant benchmark gtex --skip-missing --enforce-fixed-iterations
uv run giant benchmark panda --skip-missing --enforce-fixed-iterations
uv run giant benchmark tcga --skip-missing --enforce-fixed-iterations
uv run giant benchmark tcga_slidebench --skip-missing --enforce-fixed-iterations
uv run giant benchmark tcga_expert_vqa --skip-missing --enforce-fixed-iterations

# Optional: Patch-vote baseline for paper comparison
uv run giant benchmark panda --mode patch_vote --skip-missing
```

**Expected output location** (default `--resume`):
- `results/{dataset}_{mode}_{provider}_{model}_results.json`
- `results/checkpoints/{run_id}.checkpoint.json`
- `results/trajectories/{safe_item_id}_run{run_idx}.json`

**Note**: There is no CLI `--run-id` flag; `--resume/--no-resume` only affects run ID construction. If you need multiple distinct runs with different configs, prefer a unique `--output-dir` per run (or archive between runs) to avoid checkpoint config collisions.

---

## Storage Impact

| Category | Current Size | After Cleanup |
|----------|-------------|---------------|
| Main results JSON (`results/*_results.json`) | 456K | Archived |
| Trajectory files (`results/trajectories/`) | 1.7G | Archived |
| Checkpoint files (`results/checkpoints/`) | 476K | Archived |
| Logs (`results/*.log`) | 488K | Archived |
| E2E validation (`results/e2e_validation/`) | 1.8M | Archived |
| Backups (`results/*.bak`) | 360K | Deleted |
| Smoke tests (`results/smoke-*`) | 332K | Deleted |
| **Total archived (approx)** | 1.7G (+ 1.8M) | Moved under `_archive/` |
| **Total deleted (freed)** | 692K | Freed |

---

## Decisions Required

1. **Archive vs Delete trajectories?**
   - Archive: Preserves debugging capability for pre-fix runs
   - Delete: Saves ~1.7 GB, but loses provenance

2. **Keep e2e_validation?**
   - Resolved: archived under `results/_archive/pre-2026-01-01-fixes-20260101_192426/e2e_validation/`

3. **Run ID convention going forward?**
   - Current: `{benchmark}_{mode}_{provider}_{model}` (human-readable)
   - Alternative: `{benchmark}_{YYYYMMDD_HHMMSS}` (timestamped, allows multiple runs)

---

## Automation Script

Once approved, execute the cleanup:

```bash
#!/bin/bash
# Run this script from the repository root directory
set -euo pipefail

cd "$(git rev-parse --show-toplevel)" || { echo "Not in a git repository"; exit 1; }

# Phase 1: Archive
ARCHIVE_DIR="results/_archive/pre-2026-01-01-fixes-$(date +%Y%m%d_%H%M%S)"
mkdir -p "$ARCHIVE_DIR"

mv results/*.log "$ARCHIVE_DIR/" 2>/dev/null || true
for f in results/*_results.json; do
  [ -f "$f" ] && mv "$f" "$ARCHIVE_DIR/"
done
[ -d results/checkpoints ] && mv results/checkpoints "$ARCHIVE_DIR/"
[ -d results/trajectories ] && mv results/trajectories "$ARCHIVE_DIR/"

cat > "$ARCHIVE_DIR/README.md" << EOF
# Pre-2026-01-01 Fixes Results Archive

Created: $(date -Iseconds)

Contains benchmark artifacts generated before:
- BUG-040 P1-2: OpenAI schema constraint hardening
- BUG-041: Fixed iteration enforcement
- BUG-042: Patch vote baseline

Note: GTEx/TCGA/PANDA artifacts are also pre-BUG-038 parsing hardening; ExpertVQA/SlideBench were generated after BUG-038 but before BUG-040/041/042.

These results may contain parsing failures that are fixed in current code.
EOF

# Phase 2: Delete noise
rm -f results/*.bak
rm -rf results/smoke-*

echo "Cleanup complete. Ready for fresh benchmark runs."
```

---

## Sign-Off

- [ ] Senior review completed
- [ ] Archive location approved
- [ ] Deletion list approved
- [ ] Rerun priority order confirmed
- [ ] Storage budget verified (archive takes ~1.7 GB)
