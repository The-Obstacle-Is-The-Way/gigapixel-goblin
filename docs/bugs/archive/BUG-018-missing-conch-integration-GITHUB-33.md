# BUG-018: Missing CONCH Tool Integration (Paper Ablation Gap)

## Severity: P3 (Paper ablation feature)

## Status: Open (Blocked on CONCH access)

## Description

The GIANT paper includes an ablation study (Section 6.2) where GIANT is augmented with access to the **CONCH** pathology foundation model for localized image–text retrieval. This expands the agent's action space from `{crop, answer}` to `{crop, answer, conch}`.

This repository currently implements the baseline loop (crop/answer only), so we cannot reproduce the paper’s “+ CONCH” ablation (Table 3) without implementing this optional tool.

---

## Paper Evidence (Section 6.2, Table 3)

### How CONCH Integration Works

From `_literature/markdown/giant/giant.md` (lines 232-233):

> "we augment GIANT with access to the CONCH pathology model, enabling the agent to choose at each step between continued navigation or invoking CONCH for localized image–text retrieval."

> "To use this tool, the agent supplies the current crop along with a set of textual hypotheses produced by the LMM. CONCH encodes the image and each hypothesis and returns cosine similarity scores that quantify their alignment, which GIANT can use for subsequent reasoning steps."

### CONCH Tool Interface

**Input:**
- `image`: The current crop (PIL Image or tensor)
- `hypotheses`: List of textual hypotheses generated by the LLM (e.g., `["adenocarcinoma", "squamous cell carcinoma", "benign tissue"]`)

**Output:**
- `scores`: List of cosine similarity scores between the image embedding and each hypothesis text embedding

### Paper Results (Table 3)

Numbers below are taken from Table 3 in `_literature/markdown/giant/giant.md` (lines 264-270).

| Benchmark | GPT-5 | + CONCH | Difference |
|-----------|----------------|---------|------------|
| GTEx      | 53.7%          | 63.8%   | **+10.2%** |
| TCGA      | 32.3%          | 22.0%   | -10.3%     |
| SlideBench| 58.9%          | 54.3%   | -4.6%      |
| PANDA     | 23.2%          | 25.5%   | +2.3%      |
| ExpertVQA | 57.0%          | 60.9%   | +3.9%      |

### Failure Mode (from paper)

> "the limited improvement on complex tasks may partly stem from the agent generating incorrect hypotheses, using CONCH to reinforce them"

This is important: CONCH can amplify confirmation bias if the LLM generates bad hypotheses.

---

## What This Requires (Behavior)

At each navigation step, the agent must be able to choose between:
- `crop`: existing behavior (request next region)
- `answer`: existing behavior (final answer)
- `conch`: provide the current crop plus a set of LMM-generated hypotheses; receive similarity scores and incorporate them into subsequent reasoning

---

## Unknowns / Not Specified in the GIANT Paper

The GIANT paper does not specify:
- CONCH preprocessing details (patch size, normalization, etc.)
- embedding dimensionality
- the exact number/formatting of hypotheses
- how similarity scores are formatted back into the LMM context

Implementation should therefore:
- rely on CONCH’s official preprocessing/inference utilities where possible
- treat embeddings as opaque and only expose cosine similarity scores upstream

---

## Implementation Plan (Aligned With This Codebase)

### 1. Protocol + Schemas

This codebase models step output as `StepResponse(reasoning, action)` with a discriminated union in `src/giant/llm/protocol.py` (`action_type`).

Add a third action model:
- `ConchAction` with `action_type: Literal["conch"]` and `hypotheses: list[str]`

Then update both schemas used for structured output:
- `src/giant/llm/schemas.py` (`step_response_json_schema` and `step_response_json_schema_openai`)
- `src/giant/llm/openai_client.py` (`_normalize_openai_response` to normalize the flattened action fields)

### 2. Tool Interface

Create a minimal interface (exact implementation depends on CONCH artifacts/access):

- `ConchTool.score_hypotheses(image, hypotheses) -> list[float]`

The agent should never depend on CONCH embedding shapes; it only needs the list of float scores aligned to the input hypotheses.

### 3. Agent Loop + Context

In `src/giant/agent/runner.py`:
- add config flags to `AgentConfig` (defined in this file), e.g. `enable_conch: bool = False`
- when `action_type == "conch"`, call the tool with the *current* observation image/crop and hypotheses
- append a textual observation containing the scores (e.g., top-k sorted) to the next-step user message so the LMM can use the signal

### 4. Trajectory Recording (Optional but Recommended)

The paper discusses “inspection of reasoning traces” in the CONCH ablation (Sec 6.2), so recording CONCH invocations improves debuggability.

Minimal requirement: persist hypotheses + scores in the saved trajectory JSON for later analysis/visualization.

---

## External Dependency Notes

The paper identifies CONCH as a distinct pathology model ([16]). The public HuggingFace listing indicates the model is gated (`gated: manual`):
- https://huggingface.co/api/models/MahmoodLab/CONCH

This means “paper-faithful” evaluation of the “+ CONCH” ablation will require obtaining access to CONCH weights or equivalent artifacts.

---

## Implementation Checklist (Engineering)

- [ ] Add `ConchAction` to `src/giant/llm/protocol.py`
- [ ] Update structured-output schemas in `src/giant/llm/schemas.py` and `src/giant/llm/openai_client.py`
- [ ] Add `enable_conch` + related config to `AgentConfig` in `src/giant/agent/runner.py` (default disabled)
- [ ] Implement `ConchTool` behind an optional dependency / feature flag
- [ ] Feed CONCH scores into the next step context and persist in trajectories
- [ ] Add unit tests for parsing + agent behavior; add integration test gated on model access

---

## References

- GIANT paper: `_literature/markdown/giant/giant.md` (Sec 6.2, Table 3)
- HuggingFace model listing (gated): https://huggingface.co/api/models/MahmoodLab/CONCH
